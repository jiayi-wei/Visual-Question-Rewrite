{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DUTOJY1Z-5fy"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "colab_type": "code",
    "id": "j_HLkLk6M05d",
    "outputId": "e5dc19b2-604e-4d40-9f81-ebfdaaf2a5af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-for-tf2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/5c/6439134ecd17b33fe0396fb0b7d6ce3c5a120c42a4516ba0e9a2d6e43b25/bert-for-tf2-0.14.4.tar.gz (40kB)\n",
      "\r",
      "\u001b[K     |████████                        | 10kB 20.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▏               | 20kB 6.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 30kB 7.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 40kB 3.7MB/s \n",
      "\u001b[?25hCollecting py-params>=0.9.6\n",
      "  Downloading https://files.pythonhosted.org/packages/a4/bf/c1c70d5315a8677310ea10a41cfc41c5970d9b37c31f9c90d4ab98021fd1/py-params-0.9.7.tar.gz\n",
      "Collecting params-flow>=0.8.0\n",
      "  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
      "Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n",
      "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.4-cp36-none-any.whl size=30114 sha256=bafcdc0143e402904cc9b80c8af5cccd9c5c7ffa03207e7c035e10d35035bd52\n",
      "  Stored in directory: /root/.cache/pip/wheels/cf/3f/4d/79d7735015a5f523648df90d871ce8e89a7df8185f7703eeab\n",
      "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for py-params: filename=py_params-0.9.7-cp36-none-any.whl size=7302 sha256=a2504ec0d721270e6642ff60c10552d82ed195d598bb8769cbd3e3398bb325e3\n",
      "  Stored in directory: /root/.cache/pip/wheels/67/f5/19/b461849a50aefdf4bab47c4756596e82ee2118b8278e5a1980\n",
      "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for params-flow: filename=params_flow-0.8.2-cp36-none-any.whl size=19473 sha256=df6de92fe4f0a27adc48e7d5e7097c0d1c993d97dfd48450eb6f7cbec4c921f6\n",
      "  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n",
      "Successfully built bert-for-tf2 py-params params-flow\n",
      "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
      "Successfully installed bert-for-tf2-0.14.4 params-flow-0.8.2 py-params-0.9.7\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-for-tf2\n",
    "import bert\n",
    "FullTokenizer = bert.bert_tokenization.FullTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "r6nX-LGzM_wF",
    "outputId": "75156c57-08fa-4f80-ad24-34ec3295ffe4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3WS80_5SNG42"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "root = \"./drive/My Drive/question_rewrite\"\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bydcYrwkNPrb"
   },
   "outputs": [],
   "source": [
    "def read_data(cate):\n",
    "  # read data into three lists\n",
    "  # q: original q (long)\n",
    "  # new_q: shorten q\n",
    "  # img: img_path\n",
    "  path = os.path.join(root, cate, 'data.json')\n",
    "  q, new_q, img = [], [], []\n",
    "  with open(path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "  for item in data:\n",
    "    q.append(item['rewrite_q'])\n",
    "    new_q.append(item['new_q'])\n",
    "    img.append(item['img_path'])\n",
    "  return q, new_q, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lBDFQpO2NhpI"
   },
   "outputs": [],
   "source": [
    "def get_model(name, fc):\n",
    "  if name == 'vgg19' and not fc:\n",
    "    model = tf.keras.applications.VGG19(include_top=False,\n",
    "                                        weights='imagenet')\n",
    "    output = model.layers[-1].output\n",
    "  elif name == 'vgg19' and fc:\n",
    "    model = tf.keras.applications.VGG19(include_top=True,\n",
    "                                        weights='imagenet')\n",
    "    output = model.layers[-3].output\n",
    "  elif name == 'res50' and not fc:\n",
    "    model = tf.keras.applications.ResNet50(include_top=False,\n",
    "                                           weights='imagenet')\n",
    "    output = model.layers[-1].output\n",
    "  else:\n",
    "    print(\"Illegal Config.\")\n",
    "  # build new image model\n",
    "  input = model.input\n",
    "  img_model = tf.keras.Model(input, output)\n",
    "  return img_model\n",
    "\n",
    "\n",
    "def feature_path(img_path, name, fc):\n",
    "  # \"./drive/My Drive/questions_rewrite/auto_annot/image/000002.jpg\"\n",
    "  # if cate=res50 and fc=False\n",
    "  # \"./drive/My Drive/questions_rewrite/auto_annot/image/000002_res50_nonfc.npy\"\"\n",
    "  p, img_name = img_path.rsplit('/', 1)\n",
    "  new_name = img_name.split('.')[0] + \"_{}_{}.npy\"\n",
    "  fc_ = 'fc' if fc else 'nonfc'\n",
    "  new_name = new_name.format(name, fc_)\n",
    "  return os.path.join(p, new_name)\n",
    "\n",
    "\n",
    "def extract_img_feat(cate, img_data, name='res50', fc=False):\n",
    "  # set the image model accoding to the name and fc config\n",
    "  img_model = get_model(name, fc)\n",
    "\n",
    "  # load img function\n",
    "  def load_image(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, (224, 224))\n",
    "    if name == 'vgg19':\n",
    "      img = tf.keras.applications.vgg19.preprocess_input(img)\n",
    "    elif name == 'res50':\n",
    "      img = tf.keras.applications.resnet.preprocess_input(img)\n",
    "    else:\n",
    "      print(\"Illegal Name.\")\n",
    "    return img, image_path\n",
    "\n",
    "  # get unique images\n",
    "  unique_img = list(set(img_data))\n",
    "  unique_img = list(map(lambda x: os.path.join(root, cate, x), unique_img))\n",
    "\n",
    "  # build dataset for unique images\n",
    "  image_dataset = tf.data.Dataset.from_tensor_slices(unique_img)\n",
    "  image_dataset = image_dataset.map(\n",
    "      load_image,\n",
    "      num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(64)\n",
    "\n",
    "  print(\"Model and Dataset Done.\")\n",
    "\n",
    "  # extract features and save\n",
    "  for img, path in image_dataset:\n",
    "      batch_features = img_model(img)\n",
    "      # reshpae image features\n",
    "      # vgg19 without top: [7*7, 512]\n",
    "      # vgg19 with top: [4096]\n",
    "      # res50 without top: [7*7, 2048]\n",
    "      if not fc:\n",
    "        batch_features = tf.reshape(batch_features, \n",
    "                                      (batch_features.shape[0],\n",
    "                                      -1, batch_features.shape[-1]))\n",
    "      for f, p in zip(batch_features, path):\n",
    "        path_of_feature = feature_path(p.numpy().decode(\"utf-8\"), name, fc)\n",
    "        np.save(path_of_feature, f.numpy())\n",
    "\n",
    "  print(\"Extraction Done.\")\n",
    "\n",
    "  # exchange img_data with feature path\n",
    "  for i in range(len(img_data)):\n",
    "    img_data[i] = feature_path(os.path.join(root, cate, img_data[i]), name, fc)\n",
    "  \n",
    "  return img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "n0hDXSncNi4l",
    "outputId": "0554eb8c-f1d3-49eb-d27e-6149abb952c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 1s 0us/step\n",
      "Model and Dataset Done.\n",
      "Extraction Done.\n"
     ]
    }
   ],
   "source": [
    "cate = \"human_annot\"\n",
    "img_model_name = 'res50'\n",
    "fc_top = False\n",
    "q_data, new_q_data, img_data = read_data(cate)\n",
    "img_data = extract_img_feat(cate,\n",
    "                            img_data,\n",
    "                            name=img_model_name,\n",
    "                            fc=fc_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XrHZ-A4iNmPi"
   },
   "outputs": [],
   "source": [
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\",\n",
    "                            trainable=True)\n",
    "\n",
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "bert_tokenizer = FullTokenizer(vocab_file, do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GBTemBxZNmGn"
   },
   "outputs": [],
   "source": [
    "def get_masks(tokens, max_seq_length):\n",
    "  if len(tokens) > max_seq_length:\n",
    "    raise IndexError(\"Token longer than max_seq_length.\")\n",
    "  return [1] * len(tokens) + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "\n",
    "def get_segments(tokens, max_seq_length):\n",
    "  if len(tokens) > max_seq_length:\n",
    "    raise IndexError(\"Token longer than max_seq_length.\")\n",
    "  segments = []\n",
    "  current_segment_id = 0\n",
    "  for token in tokens:\n",
    "    segments.append(current_segment_id)\n",
    "    if token == \"[SEP]\":\n",
    "      current_segment_id = 1\n",
    "  return segments + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "\n",
    "def get_ids(tokens, tokenizer, max_seq_length):\n",
    "  token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "  input_ids = token_ids + [0] * (max_seq_length - len(token_ids))\n",
    "  return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5fya0gPvNl4Y"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "94hJO4ruNllB"
   },
   "outputs": [],
   "source": [
    "def preprocess_sentence(w):\n",
    "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "  w = re.sub(r'[\" \"]+', \" \", w)\n",
    "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "  w = w.strip()\n",
    "  # w = \"[CLS] \" + w + \" [SEP]\"\n",
    "  return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7UfNj9N4OS3U"
   },
   "outputs": [],
   "source": [
    "def bert_preprocess(qs, tokenizer):\n",
    "   max_length = 0\n",
    "   qs_tokens = []\n",
    "   for q in qs:\n",
    "     q_data = preprocess_sentence(q)\n",
    "     tokens = tokenizer.tokenize(q)\n",
    "     tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
    "     max_length = max(max_length, len(tokens))\n",
    "     qs_tokens.append(tokens)\n",
    "\n",
    "   ids = []\n",
    "   masks = []\n",
    "   segments = []\n",
    "   for q_tokens in qs_tokens:\n",
    "     ids.append(get_ids(q_tokens, tokenizer, max_length))\n",
    "     masks.append(get_masks(q_tokens, max_length))\n",
    "     segments.append(get_segments(q_tokens, max_length))\n",
    "   return ids, masks, segments, max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OFkHr2CPOSzU",
    "outputId": "56f71273-4669-4ef5-d0ea-c28f2d2ec62b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241 31\n"
     ]
    }
   ],
   "source": [
    "input_ids, input_masks, input_segments, input_max_length = bert_preprocess(new_q_data, bert_tokenizer)\n",
    "print(len(input_ids), len(input_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pzYx2gL_hMxr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HOeCMcU6OSu9"
   },
   "outputs": [],
   "source": [
    "def output_preprocess(qs):\n",
    "  qs = [preprocess_sentence(q) for q in qs]\n",
    "  qs = ['[CLS] ' + q + ' [SEP]' for q in qs]\n",
    "  output_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='',\n",
    "                                                           lower=False)\n",
    "  output_tokenizer.fit_on_texts(qs)\n",
    "  output_tokenizer.word_index['<pad>'] = 0\n",
    "  output_tokenizer.index_word[0] = '<pad>'\n",
    "  tokens = output_tokenizer.texts_to_sequences(qs)\n",
    "  tokens = tf.keras.preprocessing.sequence.pad_sequences(tokens,\n",
    "                                                         padding='post')\n",
    "  return tokens, output_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "j6n6sP6JOSqA",
    "outputId": "eb30c997-fcef-401b-88c2-1390259481b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241 49\n",
      "[ 2 20 16  5 17  7 21 24 25 60  4 23  6  3  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0]\n",
      "beautiful kitchen. can you please tell me dimensions? thanks!\n",
      "[CLS] beautiful kitchen . can you please tell me dimensions ? thanks ! [SEP] <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "target_ids, target_tokenizer = output_preprocess(q_data)\n",
    "print(len(target_ids), len(target_ids[0]))\n",
    "print(target_ids[0])\n",
    "print(q_data[0])\n",
    "print(target_tokenizer.sequences_to_texts(target_ids)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LnnT47iIioZ3",
    "outputId": "630eb1e1-163c-42b0-c480-bdfaae9ded68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(target_tokenizer.word_index['[CLS]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K3_QQLArOSiP"
   },
   "outputs": [],
   "source": [
    "def train_val_split(data, rate=0.8):\n",
    "  len_ = len(data)\n",
    "  return data[:int(len_ * rate)], data[int(len_ * rate):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yxrvA-3sOSYB"
   },
   "outputs": [],
   "source": [
    "train_input_ids, val_input_ids = train_val_split(input_ids)\n",
    "train_input_masks, val_input_masks = train_val_split(input_masks)\n",
    "train_input_segments, val_input_segments = train_val_split(input_segments)\n",
    "\n",
    "train_target_ids, val_target_ids = train_val_split(target_ids)\n",
    "\n",
    "train_img, val_img = train_val_split(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bShI2lZBPRBg"
   },
   "outputs": [],
   "source": [
    "def load_func(ids, masks, segs, targ, img):\n",
    "  img_tensor = np.load(img.decode('utf-8'))\n",
    "  return ids, masks, segs, targ, img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HeNxLCA7PQ94"
   },
   "outputs": [],
   "source": [
    "buffer_size = len(train_input_ids)\n",
    "batch_size = 64\n",
    "steps_per_epoch = len(train_input_ids) // batch_size\n",
    "vocab_tar_size = len(target_tokenizer.word_index) + 1\n",
    "embedding_dim = 256\n",
    "units = 768\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((train_input_ids,\n",
    "                                              train_input_masks,\n",
    "                                              train_input_segments,\n",
    "                                              train_target_ids,\n",
    "                                              train_img))\n",
    "dataset = dataset.map(lambda ids, masks, segs, targ, img:\n",
    "                          tf.numpy_function(load_func,\n",
    "                                            [ids, masks, segs, targ, img],\n",
    "                                            [tf.int32, tf.int32, tf.int32, tf.int32, tf.float32]),\n",
    "                      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4aGhMvGJPQ4q"
   },
   "outputs": [],
   "source": [
    "class TextAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units):\n",
    "    super(TextAttention, self).__init__()\n",
    "    self.W1 = tf.keras.layers.Dense(units)\n",
    "    self.W2 = tf.keras.layers.Dense(units)\n",
    "    self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, query, values):\n",
    "    query_with_time_axis = tf.expand_dims(query, 1)\n",
    "    score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)))\n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "    context_vector = attention_weights * values\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "    return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wvd2YzPjPQuS"
   },
   "outputs": [],
   "source": [
    "class ImageAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units):\n",
    "    super(ImageAttention, self).__init__()\n",
    "    self.W_I = tf.keras.layers.Dense(units)\n",
    "    self.W_Q = tf.keras.layers.Dense(units)\n",
    "    self.W_P = tf.keras.layers.Dense(1)\n",
    "    \n",
    "  def call(self, v_I, v_Q):\n",
    "    v_I_att = self.W_I(v_I)\n",
    "    v_Q_att = self.W_Q(v_Q)\n",
    "    v_Q_att = tf.expand_dims(v_Q_att, axis=1)\n",
    "    p_I = self.W_P(tf.tanh(v_I_att + v_Q_att))\n",
    "    attention_weights = tf.nn.softmax(p_I, axis=1)\n",
    "\n",
    "    v_att = p_I * v_I\n",
    "    v_att = tf.reduce_sum(v_att, axis=1)\n",
    "\n",
    "    return v_att, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oomJPZSpPfai"
   },
   "outputs": [],
   "source": [
    "class QRewriteModel(tf.keras.Model):\n",
    "  def __init__(self,\n",
    "               vocab_tar_size,\n",
    "               embedding_dim,\n",
    "               dec_units,\n",
    "               batch_size):\n",
    "    super(QRewriteModel, self).__init__()\n",
    "    self.batch_size = batch_size\n",
    "    self.dec_units = dec_units\n",
    "    self.dec_embedding = tf.keras.layers.Embedding(vocab_tar_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.fc = tf.keras.layers.Dense(vocab_tar_size)\n",
    "\n",
    "    # self.encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
    "    #                              trainable=False)\n",
    "    self.text_attention = TextAttention(self.dec_units)\n",
    "    self.img_attention = ImageAttention(self.dec_units)\n",
    "    self.img_fc = tf.keras.layers.Dense(self.dec_units)\n",
    "\n",
    "  def call(self, x, hidden, enc_output, img_feature):\n",
    "    text_vector, text_weights = self.text_attention(hidden, enc_output)\n",
    "    img_feature = self.img_fc(img_feature)\n",
    "    image_vector, image_weights = self.img_attention(img_feature, hidden)\n",
    "\n",
    "    x = self.dec_embedding(x)\n",
    "\n",
    "    x = tf.concat([tf.expand_dims(text_vector, 1),\n",
    "                   tf.expand_dims(image_vector, 1),\n",
    "                   x], axis=-1)\n",
    "    output, state =  self.gru(x)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    x = self.fc(output)\n",
    "    return x, state, text_weights, image_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ju4-FjLPPfUw"
   },
   "outputs": [],
   "source": [
    "decoder = QRewriteModel(vocab_tar_size,\n",
    "                        embedding_dim,\n",
    "                        units,\n",
    "                        batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oWPH5nvk_CGK"
   },
   "outputs": [],
   "source": [
    "input_word_ids = tf.keras.layers.Input(shape=(input_max_length,),\n",
    "                                       dtype=tf.int32,\n",
    "                                       name=\"input_word_ids\")\n",
    "input_mask = tf.keras.layers.Input(shape=(input_max_length,),\n",
    "                                   dtype=tf.int32,\n",
    "                                   name=\"input_mask\")\n",
    "segment_ids = tf.keras.layers.Input(shape=(input_max_length,),\n",
    "                                    dtype=tf.int32,\n",
    "                                    name=\"segment_ids\")\n",
    "\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "encoder = tf.keras.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=[pooled_output, sequence_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4bdt8yNh_FoC"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
    "                                                            reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iG_cDmsLP1mO"
   },
   "outputs": [],
   "source": [
    "exp_name = img_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2m8N-VtOP3YA"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "T6zBs-8YnLe8",
    "outputId": "ab14d1da-3523-496b-dc24-84b68cd570ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: (64, 31)\n",
      "mask: (64, 31)\n",
      "segments: (64, 31)\n",
      "output_ids: (64, 49)\n",
      "img: (64, 49, 2048)\n"
     ]
    }
   ],
   "source": [
    "example_input_ids, example_mask, example_seg, example_output_ids, example_img = next(iter(dataset))\n",
    "print(\"input_ids:\", example_input_ids.shape)\n",
    "print(\"mask:\", example_mask.shape)\n",
    "print(\"segments:\", example_seg.shape)\n",
    "print(\"output_ids:\", example_output_ids.shape)\n",
    "print(\"img:\", example_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PCkOIZT5P5XJ"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(enc_hidden, enc_output, img, targ):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([target_tokenizer.word_index['[CLS]']] * batch_size, 1)\n",
    "\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      predictions, dec_hidden, _, _ = decoder(dec_input,\n",
    "                                              dec_hidden,\n",
    "                                              enc_output,\n",
    "                                              img)\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "  variables = decoder.trainable_variables\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Bu9aWZpUP-wN",
    "outputId": "83bc08e3-2e1c-4859-ac5b-deef122c5088"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 2.8392\n",
      "Epoch 1 Batch 1 Loss 2.5437\n",
      "Epoch 1 Batch 2 Loss 2.3330\n",
      "Epoch 1 Loss 2.5720\n",
      "Time taken for 1 epoch 50.0321159362793 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.3370\n",
      "Epoch 2 Batch 1 Loss 2.4786\n",
      "Epoch 2 Batch 2 Loss 2.2778\n",
      "Epoch 2 Loss 2.3645\n",
      "Time taken for 1 epoch 4.656791925430298 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 2.2813\n",
      "Epoch 3 Batch 1 Loss 2.0684\n",
      "Epoch 3 Batch 2 Loss 2.0645\n",
      "Epoch 3 Loss 2.1381\n",
      "Time taken for 1 epoch 2.5919201374053955 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.9049\n",
      "Epoch 4 Batch 1 Loss 1.9456\n",
      "Epoch 4 Batch 2 Loss 2.0907\n",
      "Epoch 4 Loss 1.9804\n",
      "Time taken for 1 epoch 4.500836133956909 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.9739\n",
      "Epoch 5 Batch 1 Loss 1.9271\n",
      "Epoch 5 Batch 2 Loss 1.8593\n",
      "Epoch 5 Loss 1.9201\n",
      "Time taken for 1 epoch 2.6015875339508057 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 2.0298\n",
      "Epoch 6 Batch 1 Loss 1.8870\n",
      "Epoch 6 Batch 2 Loss 1.8434\n",
      "Epoch 6 Loss 1.9201\n",
      "Time taken for 1 epoch 4.518457412719727 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 1.7868\n",
      "Epoch 7 Batch 1 Loss 1.8547\n",
      "Epoch 7 Batch 2 Loss 2.1086\n",
      "Epoch 7 Loss 1.9167\n",
      "Time taken for 1 epoch 2.6544718742370605 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 1.9091\n",
      "Epoch 8 Batch 1 Loss 1.7814\n",
      "Epoch 8 Batch 2 Loss 1.9796\n",
      "Epoch 8 Loss 1.8900\n",
      "Time taken for 1 epoch 5.185758829116821 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.9300\n",
      "Epoch 9 Batch 1 Loss 1.8464\n",
      "Epoch 9 Batch 2 Loss 1.8261\n",
      "Epoch 9 Loss 1.8675\n",
      "Time taken for 1 epoch 2.833693504333496 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 2.0590\n",
      "Epoch 10 Batch 1 Loss 1.7490\n",
      "Epoch 10 Batch 2 Loss 1.7503\n",
      "Epoch 10 Loss 1.8528\n",
      "Time taken for 1 epoch 11.895143032073975 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  total_loss = 0\n",
    "\n",
    "  for batch, (ids, masks, segments, targ, img) in enumerate(dataset):\n",
    "    enc_hidden, enc_output = encoder([ids, masks, segments])\n",
    "    batch_loss = train_step(enc_hidden, enc_output, img, targ)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "    print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                 batch,\n",
    "                                                 batch_loss.numpy()))\n",
    "    \n",
    "  if (epoch + 1) % 2 == 0:\n",
    "    checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "  \n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vh0d6X8HQMW9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
